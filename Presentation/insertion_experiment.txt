[титульный слайд]
***докладчик представляется***

[на слайде - краткий обзор доклада]
В начале я расскажу, почему вставка
нескольких тысяч строк в базу с использованием Entity Framework - 
плохая идея. Потом мы посмотрим на универсальную альтернативу - множественную
вставку с использованием процедур на базе. Дальше мы перейдём к основной теме доклада -
postgres-специфичному механизму бинарного импорта, пощупаем партиционирование,и я расскажу
про выработанные нами best-practises.

[на слайде - код модели в C#]
В качестве примера модели для вставки я выбрал звонок,
потому что для эксперимента она очень показательна - 
в модели есть все частно используемые типы данных - строки, timestmp`ы, числа и
даже enum.

[на слайде - скрипт создания таблицы]
Вот так будет выглядеть таблица в базе. Я специально увеличил
размер поля call_id, чтобы сделать строку "увесистее", и на каждый
столбец в таблице я создал индекс - я создал условия, приближенные к боевым,
потому что на практике вряд ли кто-то будет делать большие таблицы без индексов -
скорее всего потребуется возможность быстрого поиска.

[на слайде - код вставки с использованием EF] 
Код на слайде - это традиционный подход для импорта моделек из
управляемого кода в базу данных. Мы создаём конекст базы данных, прикрепляем к нему
модели, и потом отправляем изменения в таблицу. 
Это простой и хороших подход - он универсален: если мы перенесём приложение
на другую базу данных, то нам не нужно будет менять код. Код, который вы видите на слайде,
сработает и на Postgres, и в Oracle, и в MySQL. И кода не так много - всего три строчки.
Небольшое количество кода снижает вероятность вознкновения бага, и программу с маленькой
кодовой базой легче поддерживать.
Однако есть одно большое "НО", которое перечёркивает все достоинства вставки через контекст - 
она медленная, жукто медленная!!

[на слайде - график: время=вставка(кол-во строк)]
Посмотрите: на вставку 10 000 строк ушло целых 2 секунды! (2 секунды, Каарррл!!)
Причём при построении этого графика, для чистоты эксперимента, база была развёрнута на одной
машине с приложением. Однако зачастую база находится на удалённом сервере - нам нужно 
передавать данные по сети. А это - ещё +время. По опыту скажу, что время может увеличится
ещё на несколько секунд - до 3-5.
Для приложений, которые должны иметь высокую пропускную способность, это непозволительно медленно. 
Подумайте - чтобы вставить в базу хотя бы миллион строк, нужно 3-5 минут.
Если цель вашего приложения - вставлять в базу миллион строк в минуту, и код, который
вы написали, умеет производить эти данные, то вы безнадёжно застрянете
на низкой пропускной способности базы.

[на слайде - сгенерированный EF`ом SQL]
INSERT INTO calls (call_id, call_type, called_number, calling_number, duration, end_time, start_time)
VALUES (@p42, @p43, @p44, @p45, @p46, @p47, @p48);
INSERT INTO calls (call_id, call_type, called_number, calling_number, duration, end_time, start_time)
VALUES (@p42, @p43, @p44, @p45, @p46, @p47, @p48);
.....
Медленная вставка - это проблема. Чтобы её решить, нужно разобраться, где зарыт корень зла.
EF для каждой строки генерирует отдельный INSERT.Каждый INSERT запрашивает lock на таблицу, все
INSERT`ы выполняются последовательно. Вот и узкое место!

[на слайде -скрины готовых библиотечек]
На самом деле - проблема медленной вставки через конекст известна сообществу
уже давно, и написано несколько готовых решений. Но эти библиотеки либо сделаны
под SqlServer (SQLBulkCopy), либо продаются за деньги (EntityFrameworkExtensions).
Простите, но покупать библиотеку за деньги....не вариант, мягко говоря.
Поэтому лучше будет написать быструю вставку самим!

[на слайде - два графика в одной системе координат: ef+новый скоростной]
Первое самописное решение - вставка с использованием процедуры на базе.
Как видно на графике - использование процедуры дало прирост в скорости в 3-4 раза. Это круто.
Давайте посмотрим, засчёт чего это достигается.

[на слайде-процедура на SQL+скрипт создания composite type]
Мы создаём в базе специальный тип данных (называется composite type), в управляемом коде
устанавливаем ассоциацию между нашей моделью и этим типом, а потом вызываем вот эту процедуру и 
подаём ей как параметр массив наших моделек.
Внутри процедуры - INSERT внутри FOREACH. Postgres умеет оптимизировать такую составную конструкцию
и поэтому вставка происходит быстрее, чем через тысячу последовательно написанных INSERT`ов, как это
делает EF. Прирост в скорости - налицо.

[на слайде -плюсы и минусы этого подхода]
Подход хорош, - он решает проблему скорости вставки. Вставка теперь быстрая.
К тому же,точно такую же вставку можно сделать и в Oracle.
Есть и минусы. Первый минус - маппинг модели из управляемого кода на composite type.
В нашем простом примере мы привязали модель к composite type одной строчкой. Но что, если,
к примеру, вы храните enum в базе как число,а не как отдельный postgres`овый тип? Тогда
нужно будет по-честному создать ещё один класс, где вместо enum`а будет какой-нибудь short,
намаппить исходную модель на этот класс, и отправлять в процедуру именно полученные "копии".
Создаётся нагрузка на GC. Если вам понадобилсь быстро вставлять данные, значит, вы их много производите,
верно? После такого маппинга данных будет в два раза больше, и GC будет приезжать на кучу чаще.
Как следствие - приложение чаще приостанавливает потоки, снижается пропускная способность.
Второй минус - это наличие в вашем приложении неуправляемого кода на базе. Если вы что-то изменили в 
модели, то запросто можете забыть поменять процедуру - в лучшем случае при вставке выпадет exception,
а в худшем - вы получите искажение данных из-за кастов между типами.

[на слайде - три графика: ef+composite type+ следующая супер-вставка]
Выход, как всегда, есть :)
Дамы и господа, представляю вашему вниманию binary copy, также известный
как бинарный импорт в таблицу. Он вставляет данные в таблицу ещё быстрее процедуры,
и не создаёт дополнительной нагрузки для GC.

[на слайде - пример SQL команды COPY]
При бинарной вставке на стороне управляемого кода формируется последовательность
байт в строго определённом стандартом postgres`а формате. Потом мы вызываем 
команду COPY и через STDIN отдаём ей эти байты. Postgres расшифровывает эти байты,
вставляет значения в нужные столбцы, и если всё пройдёт без ошибок, COPY вернёт
число успешно вставленных строк.

[на слайде - схема байт в бинарном потоке]
Давайте подробнее рассмотрим сему расположения байт. Поток можно разделить на три части:
заголовок, область данных и окончание.Длина заголовка - 15 байт.В начале заголовка должна быть так называемая
"сигнатура" - 11 байт PGCOPY\n\377\r\n\0. Если бинарный поток при передаче прошёл через меняющие байты фильтры,
например, через фильтры, меняющие концы строк или отбрасывающие нулевые байты, то данные исказятся, и об искажении
мы узнаем именно из измененния сигнатуры - она спроектирована так, чтобы искажающие данные фильтры изменили и её тоже.
Следующие 4 байта - это поле флагов. Сейчас эти флаги почти не используются (биты-нулевые), это, скорее, задел на будущее.
После заголовка идёт 4х байтовое число - оно указывает дополнительный размер заголовка. Это тоже задел на будущее,
эти 4 байта позволяют расширять заголовок до практически неограниченной длины. Сейчас там всегда 0.
Сразу после заголовка идут данные. Каждая вставляемая строка начинается с 16-битного числа, определяющего
количество столбцов. После идут столбцы. Перед каждым столбцом - 32-байтовое число, обозначающее длину типа данных в столбце,
и само значение. Примечательно, что если мы пишем в столбец NULL, то вместо длины типа данных нужно указать -1, и далее
может сразу идти длина следующего столбца. Так сокращается объём байт, нужный на передачу NULL.
Окончание потока - это всего лишь одно 16-байтовое число, в нём всегда записано -1. Интерпретатор бинарного потока
считывает строки (напомню,каждая строка начинается с 16-байтового количества столбцов), при считывании следующей строки
получает количество столбцов == -1, и понимает, что запись окончена.

[на слайде - код на C#]
Вы наверно подумали, что мы будем самостоятельно переводить наши CLR-типы в байты :)
Как бы не так! К счастью (или к сожалению), в Npgsql предусмотрен класс BinaryWriter,
который умеет сам начинать и заканчивать бинарный импорт (т.е. писать заголовок и окончание),
а также переводить CLR-типы в байты, согласно байтовому представлению соответсвующего типа в
Postgres. 
Вот так просто и красиво это выглядит в коде.
Мы создаём BinaryWriter, указываем в "сыром" SQL команду COPY,
которая будет принимать наш бинарный поток,потом с помощью метода Write записываем значение поля нашей модели
в бинарный поток с указанием типа соответствующего столбца в Postgres.
Метод Complete() заканчивает запись (добавляет -1 в конец бинарного потока) и исполняет команду COPY на базе.

[на слайде-ещё один код на C#]
BinaryWriter удобен в использовании, с помощью него можно
быстро написать бинарную вставку. 
Однако на случай, если вы решите шифровать байты самостоятельно,в Npgsql
предусмотрительно добавлено Stream API - да-да, вы точно также пишете команду COPY,
только в STDIN подставляется .Net Stream.
В этом случае ответственность за формирование бинарного потока ложится только на вас.

[на слайде -график возрастающей линейной функции:)]
Отлично! Мы нашли самый быстрый метод вставки в таблицы Postgres`а.
Ура! Теперь можно мы можем вставлять сотни тысяч строк в минуту. Давайте вставим,
для примера, 10 миллионов строк.
График, который вы видите на слайде - это зависимость процента утилизации CPU  машины, на которой развёрнута база, от времени,
на протяжении вставки этих 10 миллионов строк.
Как видите, после того, как мы вставили 5-ый миллион записей, утилизация почему-то достигла 90%.
Кто может сказать, почему?
-Это как-то связано с чтением с диска?
Да, верно! Вспомните, на каждом столбце таблицы calls стоит индекс. Индекс - это структура данных, обычно - бинарное дерево.
Чтобы поддерживать высокую скорость навигации по индексу, дерево должно быть сбалансированным - то есть периодически оно перестраиватся.
Для перестроения индекса база использует оперативную память. Когда индекс становится большим - N гигабайт, он не умещается в память, и база
в процессе пересроения несколько раз загружает-выгружает отдельные куски с диска. В Unix-ситемах этот процесс (загрузки-выгрузки отдельных страниц из рабочей памяти на диск)
называется SWAP.

/*
Следующие N слайдов - рассказ об особенностях Postgres (о том, как в базе реализовано взаимодействие между памятью и диском)
Я расскажу также про work_mem и shared_buffers - как изменение их дефолтных значений в конфигах базы позволит уменьшить число trip`ов 
на диск. С картинками :) И, конечно же, объясню, чем опасен SWAP для СХД.
*/

/*
Потом покажу, как партиционирование позволяет избавиться от SWAP (засчёт локальных индексов на партициях,которые умещаются в память).
Посмотрим "теорию" партиционирования в Postgres (способы партиционирования, как устроена партиционированая таблица в базе, как за логарифм 
query planner роутит запрос между таблицами). Сравним с партиционированием в других реляционных БД.
*/

/*
В заключение - свяжем бинарный импорт и партиционирование воедино. Оказывается, для COPY
нужно явно указывать партицию. Приведём пример, как мы роутим вставку между партициями 
(для получения списка партиций из базы нужна процедурка, работащая с определёнными каталогами Postgres`а)
и генерируем партиции по мере необходимости.
Обсудим оптимальное количество записей в одной партиции, и единоразовый размер вставки через COPY, который
обеспечивает максимальную пропускную способность вставки (полученный через эксперимент).
3 октября вышла Postgres 12 - расскажу, как там изменился механизм COPY, обсудим плюсы и минусы новых фич.
*/