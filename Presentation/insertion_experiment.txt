[титульный слайд]
Привет, я Женя и я участвую в разработке одного из внутренних сервисов Телефонии Tinkoff.ru
И вот однажды этот небольшой внутренний сервис столкнулся с проблемой импорта в базу большого объёма данных.
Данные вставлялись в базу в 30-40 раз медленнее, чем они производились. Чтобы решить эту проблему, мы иссследовали
несколько возможных вариантов быстрой вставки записи в Postgres, нашли лучший. Доклад - о нём.

[на слайде - краткий обзор доклада]
Но в начале я расскажу, почему вставка
нескольких тысяч строк в базу с использованием Entity Framework - 
плохая идея. Затем мы посмотрим на универсальную альтернативу - множественную
вставку с использованием процедур на базе. И наконец, перейдём к основной теме доклада -
postgres-специфичному механизму бинарного импорта, пощупаем партиционирование,и я расскажу
про выработанные нами best-practises.

[на слайде - код модели в C#]
В качестве примера модели для вставки я выбрал звонок,
потому что для эксперимента она очень показательна - 
в модели есть все частно используемые типы данных - строки, timestmp`ы, числа и
даже enum.

[на слайде - скрипт создания таблицы]
Вот так будет выглядеть таблица в базе. Я специально увеличил
размер поля call_id, чтобы сделать строку "увесистее", и на каждый
столбец в таблице я создал индекс - я создал условия, приближенные к боевым,
потому что на практике вряд ли кто-то будет делать большие таблицы без индексов -
скорее всего потребуется возможность быстрого поиска.

[на слайде - код вставки с использованием EF] 
Код на слайде - это традиционный подход для импорта моделек из
управляемого кода в базу данных. Мы создаём конекст базы данных, прикрепляем к нему
модели, и потом отправляем изменения в таблицу. 
Это простой и хороших подход - он универсален: если мы перенесём приложение
на другую базу данных, то нам не нужно будет менять код. Код, который вы видите на слайде,
сработает и на Postgres, и в Oracle, и в MySQL. И кода не так много - всего три строчки.
Небольшое количество кода снижает вероятность вознкновения бага, и программу с маленькой
кодовой базой легче поддерживать.
Однако есть одно большое "НО", которое перечёркивает все достоинства вставки через контекст - 
она медленная, жукто медленная!!

[на слайде - график: время=вставка(кол-во строк)]
Посмотрите: на вставку 10 000 строк ушло целых 2 секунды! (2 секунды, Каарррл!!)
Причём при построении этого графика, для чистоты эксперимента, база была развёрнута на одной
машине с приложением. Однако зачастую база находится на удалённом сервере - нам нужно 
передавать данные по сети. А это - ещё +время. По опыту скажу, что время может увеличится
ещё на несколько секунд - до 3-5.
Для приложений, которые должны иметь высокую пропускную способность, это непозволительно медленно. 
Подумайте - чтобы вставить в базу хотя бы миллион строк, нужно 3-5 минут.
Если цель вашего приложения - вставлять в базу миллион строк в минуту, и код, который
вы написали, умеет производить эти данные, то вы безнадёжно застрянете
на низкой пропускной способности базы.

[на слайде - сгенерированный EF`ом SQL]
INSERT INTO calls (call_id, call_type, called_number, calling_number, duration, end_time, start_time)
VALUES (@p42, @p43, @p44, @p45, @p46, @p47, @p48);
INSERT INTO calls (call_id, call_type, called_number, calling_number, duration, end_time, start_time)
VALUES (@p42, @p43, @p44, @p45, @p46, @p47, @p48);
.....
Медленная вставка - это проблема. Чтобы её решить, нужно разобраться, где зарыт корень зла.
EF для каждой строки генерирует отдельный INSERT.

[на слайде - этапы интерпретации SQL постгресом]
Каждый INSERT постгрес воспринимает, как 
отдельную команду - для которой он проводит полный анализ:
парсит текст в дерево выражений, потом проверяет каждое
выражение на корректность (например, смотрит, есть ли в базе
нужная таблица и не нарушаем ли мы constraint на столбцах),
строит план выполнения, и только потом исполняет. 
Это значительные накладные расходы - мы не только теряем в скорости,
но и процессор на базе греем :)

[на слайде -скрины готовых библиотечек]
Проблема медленной вставки через конекст известна сообществу
уже давно, и написано несколько готовых решений. Но эти библиотеки либо сделаны
под SqlServer (SQLBulkCopy), либо продаются за деньги (EntityFrameworkExtensions).
Простите, но покупать библиотеку за деньги....не вариант, мягко говоря.
Поэтому лучше будет написать быструю вставку самим!

[на слайде - два графика в одной системе координат: ef+новый скоростной]
Первое самописное решение - вставка с использованием процедуры на базе.
Как видно на графике - использование процедуры дало прирост в скорости в 3-4 раза. Это круто.
Давайте посмотрим, засчёт чего это достигается.

[на слайде-процедура на SQL+скрипт создания composite type]
Мы создаём в базе специальный тип данных (называется composite type), в управляемом коде
устанавливаем ассоциацию между нашей моделью и этим типом, а потом вызываем вот эту процедуру и 
подаём ей как параметр массив наших моделек.
Внутри процедуры - INSERT внутри FOREACH. Postgres умеет оптимизировать такую составную конструкцию
и поэтому вставка происходит быстрее, чем через тысячу последовательно написанных INSERT`ов, как это
делает EF. Прирост в скорости - налицо.

[на слайде -плюсы и минусы этого подхода]
Подход хорош, - он решает проблему скорости вставки. Вставка теперь быстрая.
К тому же,точно такую же вставку можно сделать и в Oracle.
Есть и минусы. Первый минус - маппинг модели из управляемого кода на composite type.
В нашем простом примере мы привязали модель к composite type одной строчкой. Но что, если,
к примеру, вы храните enum в базе как число,а не как отдельный postgres`овый тип? Тогда
нужно будет по-честному создать ещё один класс, где вместо enum`а будет какой-нибудь short,
намаппить исходную модель на этот класс, и отправлять в процедуру именно полученные "копии".
Создаётся нагрузка на GC. Если вам понадобилсь быстро вставлять данные, значит, вы их много производите,
верно? После такого маппинга данных будет в два раза больше, и GC будет приезжать на кучу чаще.
Как следствие - приложение чаще приостанавливает потоки, снижается пропускная способность.
Второй минус - это наличие в вашем приложении неуправляемого кода на базе. Если вы что-то изменили в 
модели, то запросто можете забыть поменять процедуру - в лучшем случае при вставке выпадет exception,
а в худшем - вы получите искажение данных из-за кастов между типами.

[на слайде - три графика: ef+composite type+ следующая супер-вставка]
Выход, как всегда, есть :)
Дамы и господа, представляю вашему вниманию binary copy, также известный
как бинарный импорт в таблицу. Он вставляет данные в таблицу ещё быстрее процедуры,
и не создаёт дополнительной нагрузки для GC.

[на слайде - пример SQL команды COPY]
При бинарной вставке на стороне управляемого кода формируется последовательность
байт в строго определённом стандартом postgres`а формате. Потом мы вызываем 
команду COPY и через STDIN отдаём ей эти байты. Postgres расшифровывает эти байты,
вставляет значения в нужные столбцы, и если всё пройдёт без ошибок, COPY вернёт
число успешно вставленных строк.

[на слайде - схема байт в бинарном потоке]
Давайте подробнее рассмотрим сему расположения байт. Поток можно разделить на три части:
заголовок, область данных и окончание.Длина заголовка - 15 байт.В начале заголовка должна быть так называемая
"сигнатура" - 11 байт PGCOPY\n\377\r\n\0. Если бинарный поток при передаче прошёл через меняющие байты фильтры,
например, через фильтры, меняющие концы строк или отбрасывающие нулевые байты, то данные исказятся, и об искажении
мы узнаем именно из измененния сигнатуры - она спроектирована так, чтобы искажающие данные фильтры изменили и её тоже.
Следующие 4 байта - это поле флагов. Сейчас эти флаги почти не используются (биты-нулевые), это, скорее, задел на будущее.
После заголовка идёт 4х байтовое число - оно указывает дополнительный размер заголовка. Это тоже задел на будущее,
эти 4 байта позволяют расширять заголовок до практически неограниченной длины. Сейчас там всегда 0.
Сразу после заголовка идут данные. Каждая вставляемая строка начинается с 16-битного числа, определяющего
количество столбцов. После идут столбцы. Перед каждым столбцом - 32-байтовое число, обозначающее длину типа данных в столбце,
и само значение. Примечательно, что если мы пишем в столбец NULL, то вместо длины типа данных нужно указать -1, и далее
может сразу идти длина следующего столбца. Так сокращается объём байт, нужный на передачу NULL.
Окончание потока - это всего лишь одно 16-байтовое число, в нём всегда записано -1. Интерпретатор бинарного потока
считывает строки (напомню,каждая строка начинается с 16-байтового количества столбцов), при считывании следующей строки
получает количество столбцов == -1, и понимает, что запись окончена.

[на слайде - код на C#]
Вы наверно подумали, что мы будем самостоятельно переводить наши CLR-типы в байты :)
Как бы не так! К счастью (или к сожалению), в Npgsql предусмотрен класс BinaryWriter,
который умеет сам начинать и заканчивать бинарный импорт (т.е. писать заголовок и окончание),
а также переводить CLR-типы в байты, согласно байтовому представлению соответсвующего типа в
Postgres. 
Вот так просто и красиво это выглядит в коде.
Мы создаём BinaryWriter, указываем в "сыром" SQL команду COPY,
которая будет принимать наш бинарный поток,потом с помощью метода Write записываем значение поля нашей модели
в бинарный поток с указанием типа соответствующего столбца в Postgres.
Метод Complete() заканчивает запись (добавляет -1 в конец бинарного потока) и исполняет команду COPY на базе.

[на слайде-ещё один код на C#]
BinaryWriter удобен в использовании, с помощью него можно
быстро написать бинарную вставку. 
Однако на случай, если вы решите шифровать байты самостоятельно,в Npgsql
предусмотрительно добавлено Stream API - да-да, вы точно также пишете команду COPY,
только в STDIN подставляется .Net Stream.
В этом случае ответственность за формирование бинарного потока ложится только на вас.

[на слайде - профайл памяти]
Все три этих способа очень по-разному потребляют память на управляемой куче.
Я сделал вставку 10_000 строк в базу, и вот что получилось - copy и composite types
скромно уложились в 20 мегабайт, а ef развернулся на все 130! это в 6 споловиной раз больше!
Ужас! КОшмар! 
Давайте разбираться, зачем ему столько памяти.
Идеи есть?
Так, смотрим. Основная часть выделений памяти пришлась на строки - это наши инсёрты,
и на создание параметров к ним их массива вставляемых сущностей.
И на сладенькое - мы загремели на large objects heap! Подумать только!
Это возмутительно! А что, если мы будем вставлять другую сущность, у которой больше
столбцов, и их названия длинее? Процент попадания на loh возрастёт.
Вставка через ef не только медленная с точки зрения базы, но ещё и с точки зрения
CLR - GC будет приезжать на кучу чаще, и приложение вслед за этим также начнёт тормозить.

[на слайде -график возрастающей линейной функции:)]
Отлично! Мы нашли самый быстрый метод вставки в таблицы Postgres`а.
Ура! Теперь можно мы можем вставлять сотни тысяч строк в минуту. 
Однако, если мы будем заполнять таблицу такими темпами, то через некоторое время
мы начнём замедляться. Каждая новая вставка будет проходить всё медленней.
На N-ом миллионе строк от былой скорости не останется и следа...
Кто может сказать, почему?
-Это как-то связано с чтением с диска?


[на слайде -схема BTREE]
Да, верно! Вспомните, на каждом столбце таблицы calls стоит индекс. Индекс - это структура данных, обычно - бинарное дерево.
Постгрес хранит индекс, также, как и таблицы - в блоках. Только у таблице в блоке сложены строки, а у индекса - ключи.
На диаграмме - индекс, состоящий из 4-х блоков. Верхний блок содержит диапазоны ключей, каждый диапазон ссылается
на блок, в котором лежат ключи из этого диапазона. Каждый ключ ссылается на блок таблицы, в котором хранится строка с этим ключём.
Блоки одного уровня составляют связный список, чтобы постгрес мог быстро выполнять запросы вида "дай мне все строки, у которых ключ больше.."
Мы просто находим нужный диапазон и  перебираем все следующие за ним. Очень просто.
BTree в постгресе имеет тенденцию расти вширь, а не вглубь. В таблице может лежать несколько миллионов записей, а индекс может иметь глубину 5.

Чтобы поддерживать высокую скорость навигации по индексу, дерево должно быть сбалансированным - то есть периодически оно перестраиватся.
Для перестроения индекса база использует оперативную память. Когда индекс становится большим - N гигабайт, он не умещается в память, и база
в процессе пересроения несколько раз загружает-выгружает отдельные блоки с диска.
В Unix-ситемах подобный процесс называется SWAP.

[на слайде -чем плох SWAP?]
Перенос информации из памяти на диск - это, как правило, задача выского приоритета для ОС.
При пересчёте нескольких больших индексов SWAP идёт всё время => остальные потоки ждут его завершения,
а значит вся система в целом перестаёт отвечать на запросы пользователя. Что это значит? Если на одной
машине развёрнуто две базы постгреса, и одна из них находится в глубоком свопе, то с точки зрения пользо-
вателя вторая база будет тормозить ничуть не меньше первой, ведь у неё совсем нет процессорного времени для исполнения запросов.
И где-то на другом конце сети какое-нибудь приложение также начнёт тормозить всед за своей базой,причём, без видимой причины - не так-то 
просто будет понять, почему запросы вдруг начали исполняться дольше обычного.

На эту ситуацию также можно взглянут с теоретико-экономической точки зрения: физическое железо, на котором стоит провалившаяся
в своп база, начинает сильно греться - процессор загружен 95-100% времени. CPU становится ну ооочень горячим - выше 60 градусов,
и система охлаждения начинает усердно отводить тепло. Оба этих процесса - работа CPU на пределе мощности и отвод тепла, тратят много
электричества, которое стоит денег. К тому же, повышается износ недешёвой системы охлаждения - сокращается срок его службы.
В качестве яркого примера можно привести суперкомпьютер Ломносов в МГУ - один день его работы стоит 20 000 долларов.
У датацентра, функционирующего на 100%, цифры будут сопоставимые. 
Что делать?

[на слайде -ВЫХОД ЕСТЬ!!]
Выход, как всегда есть. 
В чём корень зла? В больших индексах.
Можем мы отказаться от индексов? Нет. Но мы можем сделать их меньше.
Чтобы индекс был меньше, сама таблица должна содержать неможко записей.
То есть нам нужно разбить одну огромную таблицу на много маленьких, и вставлять
строки, не опасаясь свопа.

[на слайде -партиционирование]
В постгресе разбиение одной таблицы на несколько называется партиционирование.
Мы создаём одну основную таблицу, задаём критерий партиционирования - по значению какого
столбца мы будем выбирать нужную партицию для хранения, и потом делаем сколько угодно партиций.
(и не паримся :) )

[на слайде -партиционирование]
Вот например, мы делаем основную таблицу, и говорим при этом, что в каждой партиции
у нас будут лежать строки, у которых поле "дата" попадает в заданный интервал - от и до.
В примере мы делаем партцию, в которую попадут все ноябрские логи.
Ещё можно партиционировать по равенству столбца какой-нибудь константе.
В этом случае в партицию попадут логи с уровнем "ERROR"

Постгрес позволяет делать вставки и слекты с указанием имени основной таблицы. У себя под капотом
он смаршрутизирует данные в нужную партицию.
НО!
Возвращаемся к copy. Для бинарного импорта нужно явно указывать имя партиции, потому что это довольно
низкоуровневая операция.

[на слайде - выводы]
То есть , если у нас есть потребность вставлять в базу Постгреса большие объёмы данных,
то последовательность действий такова:
1)Создаём партиционированную таблицу
2)В управляемом коде перед вставкой находим подходящую партцию, если 
таковой не нашлось - генерируем сырой sql-командой
3)Делаем в эту партцию бинарный импорт через copy
Мы на проекте делаем именно так, и приложение с базой чудесно справляются с нагрузкой.

[на слайде -и напоследок]
3 го октября релизнулся 12й Постгрес - 
в нём уменьшили размер BTree - так что теперь можно делать партиции больше,
также при селекте по имени основной таблицы планировщик запросов быстрее находит нужные партиции,
если их - тысячи.
И, что самое главное - copy  теперь можно использовать для вставки в основную таблицу, Постгрес сам
найдёт нужную партицию.
Однако,с точки зрения производительности последняя фича довольно сомнительна - базе нужно выполнить
алгоритм поиска партции для каждого испортируемого элемента, а это тоже накладные расходы :)

[на слайде - ]
***конец***
++я презентую WinForms приложеньку, на которой можно
как угодно гонять эти три вставки, внося какие угодно изменения


